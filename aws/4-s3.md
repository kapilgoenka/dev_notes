# S3

### Buckets

* Amazon S3 allows people to store objects (files) in “buckets” (directories)

* Buckets must have a globally unique name (across all regions all accounts)

* Buckets are defined at the region level

* S3 looks like a global service but buckets are created in a region

* Naming convention

    * No uppercase, No underscore
    
    * 3-63 characters long
    
    * Not an IP
    
    * Must start with lowercase letter or number
    
    * Must NOT start with the prefix `xn--`
    
    * Must NOT end with the suffix `-s3alias`

<br>

### Objects

* Objects (files) have a Key

* The key is the FULL path:

    * s3://my-bucket/`my_file.txt`
    
    * s3://my-bucket/`my_folder1/another_folder/my_file.txt`

* The key is composed of `prefix` + object name

* s3://my-bucket/`my_folder1/another_folder/`my_file.txt

* There’s no concept of “directories” within buckets (although the UI will trick you to think otherwise)

* Just keys with very long names that contain slashes (“/”)

* Object values are the content of the body:

    * Max. Object Size is 5TB (5000GB)
    
    * If uploading more than 5GB, must use “multi-part upload”

* Metadata (list of text key / value pairs) – system or user metadata

* Tags (Unicode key / value pair – up to 10) – useful for security / lifecycle

* Version ID (if versioning is enabled)

<br>

### Bucket Policies

* JSON based policies

    * Resources: buckets and objects
    
    * Effect: Allow / Deny
    
    * Actions: Set of API to Allow or Deny
    
    * Principal: The account or user to apply the policy to

* Use S3 bucket for policy to:

    * Grant public access to the bucket
    
    * Force objects to be encrypted at upload
    
    * Grant access to another account (Cross Account)

<br>

### Security

* User-Based

    * IAM Policies – which API calls should be allowed for a specific user from IAM

* Resource-Based

    * Bucket Policies – bucket wide rules from the S3 console - allows cross account
    
    * Object Access Control List (ACL) – finer grain (can be disabled)
    
    * Bucket Access Control List (ACL) – less common (can be disabled)

* An IAM principal can access an S3 object if:

    * The user IAM permissions ALLOW it OR the resource policy ALLOWS it
    
    * AND there’s no explicit DENY

* Examples:

    * `Anonymous www website visitor --> S3 Bucket`: S3 Bucket Policy
    
    * `IAM User --> S3 Bucket`: IAM Policy
    
    * `EC2 Instance --> S3 Bucket`: IAM Roles
    
    * `Other AWS account IAM User --> S3 Bucket`: S3 Bucket Policy

<br>

### Static Website Hosting

* S3 can host static websites and have them accessible on the Internet

* The website URL will be (depending on the region):

	* http://bucket-name.s3-website-aws-region.amazonaws.com, OR

	* http://bucket-name.s3-website.aws-region.amazonaws.com

* If you get a 403 Forbidden error, make sure the bucket policy allows public reads!

<br>

### Versioning

* You can version your files in Amazon S3

* It is enabled at the bucket level

* Same key overwrite will change the “version”: 1, 2, 3….

* It is best practice to version your buckets

    * Protect against unintended deletes (ability to restore a version)
    
    * Easy roll back to previous version

* Notes:

    * Any file that is not versioned prior to enabling versioning will have version “null”
    
    * Suspending versioning does not delete the previous versions

<br>

### Replication

* Cross-Region Replication (CRR)

* Same-Region Replication (SRR)

* Buckets can be in different AWS accounts

* Copying is asynchronous

* Must give proper IAM permissions to S3

* Must enable Versioning in source and destination buckets

<br>

### Storage Classes

#### Standard - General Purpose

* Used for frequently accessed data

* Low latency and high throughput

<br>

#### Infrequent Access

* For data that is less frequently accessed, but requires rapid access when needed

* Lower cost than S3 Standard

    * Standard - Infrequent Access
        
        * 99.9% Availability
    
    * One Zone - Infrequent Access
    
        * High durability (99.999999999%) in a single AZ
    
        * Data lost when AZ is destroyed

<br>

#### Glacier

* Low-cost object storage meant for archiving / backup
    
    * Instant Retrieval
    
        * Millisecond retrieval, great for data accessed once a quarter
    
        * Minimum storage duration of 90 days
    
    * Flexible Retrieval
    
        * Expedited (1 to 5 minutes), Standard (3 to 5 hours), Bulk (5 to 12 hours) – free
    
        * Minimum storage duration of 90 days
    
    * Deep Archive
    
        * For long term storage
    
        * Standard (12 hours), Bulk (48 hours)
    
        * Minimum storage duration of 180 days

<br>

#### Express One Zone

* High performance, single Availability Zone storage class
    
* Handle 100,000s requests per second with single-digit millisecond latency
    
* Up to 10x better performance than S3 Standard (50% lower costs)
    
* High Durability (99.999999999%) and Availability (99.95%)
    
* Co-locate your storage and compute resources in the same AZ (reduces latency)
    
* Use cases: latency-sensitive apps, data-intensive apps, AI & ML training, financial modeling, media processing, HPC…
    
* Best inteintegrated with SageMaker Model Training, Athena, EMR ..

<br>

#### Intelligent-Tiering

* Small monthly monitoring and auto-tiering fee

* Moves objects automatically between Access Tiers based on usage

    * Frequent Access tier (automatic): default tier
    
    * Infrequent Access tier (automatic): objects not accessed for 30 days
    
    * Archive Instant Access tier (automatic): objects not accessed for 90 days
    
    * Archive Access tier (optional): configurable from 90 days to 700+ days
    
    * Deep Archive Access tier (optional): config. from 180 days to 700+ days

<br>

### IAM Access Analyzer for S3

* Ensures that only intended people have access to your S3 buckets

* Example: publicly accessible bucket, bucket shared with other AWS account ...

* Evaluates S3 Bucket Policies, S3 ACLs, S3 Access Point Policies

<br>

### Snowball

#### Edge Computing

* Process data while it’s being created on an edge location

    * A truck on the road, a ship on the sea, a mining station underground ...

    * These locations may have limited internet and no access to computing power

<br>

#### What is Snowball?

* Highly-secure, portable and `offline` devices to collect and process data at the edge, and `migrate` data into and out of AWS

* Helps migrate up to Petabytes of data

* If it takes more than a week to transfer over the network, use Snowball devices!

<br>

### Storage Gateway

* Bridge between on-premise data and cloud data in S3

* Extend on-premises storage to S3

* Hybrid storage service to allow on-premises to seamlessly use the AWS